# ğŸ° Casino Predictor Backend

API REST y CLI para anÃ¡lisis estadÃ­stico de juegos de casino.

## ğŸš€ InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv venv

# Activar (Windows)
venv\Scripts\activate

# Activar (Linux/Mac)
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸ“‹ Requisitos

- Python 3.10+
- Flask 3.0.0
- NumPy 2.1.2
- Pandas 2.0.3
- Scikit-learn 1.3.0
- Ollama (opcional, para chatbot)

## ğŸƒ Ejecutar

### Como API REST

```bash
python app.py
```

La API estarÃ¡ disponible en `http://localhost:5000`

### Como CLI (interfaz de lÃ­nea de comandos)

```bash
python main.py
```

O en modo rÃ¡pido (chat directo):
```bash
python main.py --quick
```

## ğŸ“ Estructura

```
Chatbot-py/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ predictor_casino.py    # Motor de predicciÃ³n estadÃ­stica
â”œâ”€â”€ api/
â”‚   â””â”€â”€ simulador.py           # Simulador de juegos
â”œâ”€â”€ chatbot/
â”‚   â””â”€â”€ ollama_chat.py         # Interfaz Ollama/Llama
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.py             # Funciones auxiliares
â”œâ”€â”€ data/                       # Datos generados
â”œâ”€â”€ app.py                     # API REST Flask
â”œâ”€â”€ main.py                    # CLI
â””â”€â”€ requirements.txt
```

## ğŸ® MÃ³dulos Principales

### PredictorCasino (core/predictor_casino.py)

Motor de predicciÃ³n basado en anÃ¡lisis estadÃ­stico:

```python
from core.predictor_casino import PredictorCasino

predictor = PredictorCasino(ventana_historica=100)

# Predecir ruleta
historial = [17, 5, 32, 14, ...]
prediccion = predictor.predecir_ruleta(historial)

# Predecir blackjack
cartas = ['10â™ ', 'Kâ™¥', '5â™¦', ...]
prediccion = predictor.predecir_blackjack(cartas)

# Predecir poker
mano = ['As', 'Kd']
comunitarias = ['2h', '5c', '9d']
prediccion = predictor.predecir_poker(mano, comunitarias)
```

### SimuladorCasino (api/simulador.py)

Simula juegos de casino de forma realista:

```python
from api.simulador import SimuladorCasino

simulador = SimuladorCasino()

# Simular ruleta
resultado = simulador.simular_tirada_ruleta('table_1')
# {'numero': 17, 'color': 'negro', 'paridad': 'impar', ...}

# Simular blackjack
resultado = simulador.simular_mano_blackjack('table_1')
# {'mano_jugador': ['10â™ ', 'Kâ™¥'], 'valor': 20, ...}

# Simular poker
resultado = simulador.simular_mano_poker('table_1')
# {'mano_jugador': ['As', 'Kd'], 'fase': 'flop', ...}

# Obtener mesas
mesas = simulador.obtener_mesas_disponibles('ruleta')
```

### ChatbotOllama (chatbot/ollama_chat.py)

Chatbot especializado en anÃ¡lisis de casino:

```python
from chatbot.ollama_chat import ChatbotOllama

chatbot = ChatbotOllama()

# Verificar conexiÃ³n
ok, msg = chatbot.verificar_conexion()

# Generar respuesta
respuesta = chatbot.generar_respuesta(
    pregunta="Â¿CuÃ¡l es la ventaja de la casa en blackjack?",
    contexto_prediccion={...},  # Opcional
    historial=[...]              # Opcional
)
```

## ğŸ“¡ API Endpoints

### Health Check
```
GET /health
```

Respuesta:
```json
{
  "status": "ok",
  "predictor_loaded": true,
  "simulador_loaded": true,
  "ollama_available": true,
  "mesas_activas": {...}
}
```

### Obtener Juegos
```
GET /games
```

### Obtener Mesas
```
GET /tables/<juego>
```

### Simular Jugada
```
POST /simulate
Content-Type: application/json

{
  "game": "ruleta",
  "table": "table_1"
}
```

### Obtener PredicciÃ³n
```
POST /predict
Content-Type: application/json

{
  "game": "ruleta",
  "table": "table_1"
}
```

Respuesta:
```json
{
  "prediccion": {
    "juego": "ruleta",
    "numero_predicho": 17,
    "confianza_prediccion": 8.5,
    "probabilidades_color": {
      "rojo": 52.3,
      "negro": 45.2,
      "verde": 2.5
    },
    "numeros_calientes": [...],
    "recomendacion": "..."
  }
}
```

### Chat con IA
```
POST /chat
Content-Type: application/json

{
  "message": "Â¿CuÃ¡l es la mejor estrategia para blackjack?"
}
```

Respuesta:
```json
{
  "response": "La mejor estrategia es seguir la estrategia bÃ¡sica de blackjack...",
  "contexto_detectado": false,
  "juego_detectado": null
}
```

### EstadÃ­sticas
```
GET /stats
```

### Reiniciar Mesa
```
POST /reset/<juego>/<mesa>
```

## ğŸ¤– Configurar Ollama

El chatbot requiere Ollama y un modelo LLM.

### InstalaciÃ³n de Ollama

1. Descargar desde https://ollama.ai
2. Instalar y abrir
3. En terminal ejecutar:
   ```bash
   ollama serve
   ```

### Descargar Modelo

```bash
ollama pull llama3.2:3b
```

Modelos alternativos:
- `llama3.2:1b` - Muy rÃ¡pido, menos preciso
- `llama2:7b` - MÃ¡s grande, mÃ¡s preciso (requiere mÃ¡s RAM)
- `mistral:7b` - Equilibrado

## ğŸ§ª Testing

Ejecutar ejemplo de simulador:
```bash
python api/simulador.py
```

Ejecutar ejemplo de chatbot:
```bash
python chatbot/ollama_chat.py
```

## ğŸ“Š Limitaciones Conocidas

1. **PredicciÃ³n de Ruleta**: Usa anÃ¡lisis de frecuencias (nÃºmeros calientes/frÃ­os)
   - No garantiza predicciÃ³n determinÃ­stica
   - La ruleta es aleatoria, cualquier patrÃ³n es coincidencia

2. **Blackjack**: Conteo Hi-Lo simplificado
   - Asume 6 mazos
   - No implementa todas las variantes

3. **PÃ³ker**: EvaluaciÃ³n bÃ¡sica de manos
   - No tiene en cuenta dinÃ¡mica de jugadores
   - CÃ¡lculo de outs simplificado

4. **Chatbot**: Depende de Ollama
   - Si Ollama no estÃ¡ disponible, el chat no funciona
   - Requiere conexiÃ³n a localhost

## ğŸ”’ Seguridad

- âœ… CORS restringido a localhost
- âŒ Sin autenticaciÃ³n (usar solo localmente)
- âŒ Sin validaciÃ³n robusta de inputs (MEJORAR)
- âŒ Sin rate limiting (AGREGAR)
- âŒ Sin HTTPS (AGREGAR en producciÃ³n)

## ğŸš€ ProducciÃ³n

**NO usar en producciÃ³n sin:**

1. Agregar autenticaciÃ³n
2. Validar todos los inputs
3. Implementar rate limiting
4. Usar HTTPS
5. Configurar logging a archivo
6. Agregar tests unitarios
7. Documentar cambios

## ğŸ“ Variables de Entorno

Actualmente no hay .env en Python, pero se podrÃ­a agregar:

```python
import os
API_PORT = os.getenv('API_PORT', 5000)
OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://localhost:11434')
OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'llama3.2:3b')
```

## ğŸ› Troubleshooting

### Error: "Ollama no estÃ¡ corriendo"
```bash
ollama serve
```

### Error: "Modelo no encontrado"
```bash
ollama pull llama3.2:3b
```

### Error: "Puerto 5000 en uso"
```python
# En app.py, cambiar puerto
app.run(port=5001)
```

### Error: "ModuleNotFoundError"
```bash
pip install -r requirements.txt
```

## ğŸ“– DocumentaciÃ³n

- [README Principal](../README.md)
- [API Completa](../docs/API.md) (pendiente)

## ğŸ“„ Notas

- Sistema **EDUCATIVO** Ãºnicamente
- No usar para apuestas reales
- Las predicciones son estadÃ­sticas, no garantizadas
- La casa siempre tiene ventaja matemÃ¡tica
